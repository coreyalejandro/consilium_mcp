# API Keys
MISTRAL_API_KEY=your_mistral_api_key_here
SAMBANOVA_API_KEY=your_sambanova_api_key_here
OPENAI_API_KEY=your_openai_api_key_here

# Data Collection Settings
USE_DATASET_LOGGING=1
DATASET_LOG_PATH=data/training.jsonl
QUALITY_THRESHOLD=0.7

# Training Configuration
TRAINING_MODEL=mistral-large-latest
BASE_MODEL=mistralai/Mistral-7B-v0.1
LEARNING_RATE=2e-5
BATCH_SIZE=4
EPOCHS=3
MAX_LENGTH=2048
GRADIENT_ACCUMULATION_STEPS=4

# Evaluation Settings
EVALUATION_METRICS=consensus_quality,research_depth,reasoning_clarity
EVALUATION_DATASET=data/evaluation.jsonl
BASELINE_MODEL=mistral-large-latest

# Model Management
MODEL_STORAGE_PATH=models/
WANDB_PROJECT=consilium-finetune
HUGGINGFACE_REPO=your-username/consilium-finetuned

# DSPy Configuration
DSPY_ENABLED=1
DSPY_MODEL=gpt-4
DSPY_MAX_BOOTSTRAP_DEMO=8

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/finetune.log
